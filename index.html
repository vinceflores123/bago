<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Hand Gesture Recognition</title>

    <!-- Material Components CSS -->
    <link href="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.css" rel="stylesheet">
    
    <style>
        body {
            font-family: Roboto, sans-serif;
            margin: 2em;
            color: #3d3d3d;
            --mdc-theme-primary: #007f8b;
            --mdc-theme-on-primary: #f1f3f4;
        }
    
        h1 {
            color: #007f8b;
            text-align: center;
            font-size: 2em; /* Increase for better visibility */
        }
    
        h2 {
            clear: both;
            font-size: 1.5em; /* Adjust for better readability */
        }
    
        video {
            clear: both;
            display: block;
            transform: rotateY(180deg);
            width: 100%; /* Make the video responsive */
            height: auto; /* Maintain aspect ratio */
        }
    
        section {
            opacity: 1;
            transition: opacity 500ms ease-in-out;
        }
    
        .removed {
            display: none;
        }
    
        .invisible {
            opacity: 0.2;
        }
    
        .videoView {
            display: flex;
            flex-direction: column;
            align-items: center;
            margin-top: 32px;
            min-height: 500px;
            position: relative; /* Added for absolute positioning of output */
            padding: 1em; /* Added padding for mobile spacing */
        }
    
        .videoView button,
        .videoView a {
            width: 100%; /* Full width on mobile */
            max-width: 227px; /* Limit max width */
            height: 68px;
            margin-top: 16px;
            padding: 16px;
            background-color: #007f8b;
            color: white;
            text-align: center;
            border-radius: 8px;
            cursor: pointer;
            transition: background-color 0.3s;
            font-size: 1em; /* Adjust for better visibility */
        }
    
        .videoView a {
            text-decoration: none;
        }
    
        .videoView p {
            position: absolute; /* Changed to absolute */
            bottom: 16px; /* Positioned at the bottom of the camera */
            left: 16px; /* Add some left margin */
            width: calc(100% - 32px); /* Full width minus margins */
            font-size: calc(8px + 1.2vw);
            color: white; /* Make text color visible on camera */
            background-color: rgba(0, 0, 0, 0.5); /* Semi-transparent background for readability */
            padding: 8px; /* Add some padding */
            border-radius: 8px; /* Rounded corners */
            display: none; /* Hidden by default */
        }
    
        .canvas {
            z-index: 1;
            position: absolute;
            pointer-events: none;
            width: 100%; /* Make the canvas responsive */
            height: auto; /* Maintain aspect ratio */
        }
    
/* Match canvas width with video */
        #webcam {
            width: 100%; /* Make video responsive */
            height: auto; /* Maintain aspect ratio */
        }
        
        .output_canvas {
            width: 100%; /* Match canvas width with video */
            height: 100%; /* Match canvas height with video */
            transform: rotateY(180deg); /* If needed to flip the canvas */
            z-index: 1; /* Ensure canvas is above video */
        }
        
        .output {
            position: absolute; /* Keep the output text positioned correctly */
            bottom: 16px; /* Position it at the bottom */
            left: 16px; /* Add some left margin */
            width: calc(100% - 32px); /* Full width minus margins */
            font-size: calc(8px + 1.2vw);
            color: white; /* Make text color visible */
            background-color: rgba(0, 0, 0, 0.5); /* Semi-transparent background for readability */
            padding: 8px; /* Add some padding */
            border-radius: 8px; /* Rounded corners */
        }
        /* Match canvas width with video */
    
        .output {
            display: none;
            width: 50%;
            font-size: calc(8px + 1.2vw);
        }
    
        .mdc-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
    
        /* FOR MY GUIDE IMAGES */
        #demos {
            text-align: center; /* Center the content */
        }
        
        .detectOnClick {
            text-align: center; /* Center the text and image */
            margin-bottom: 10px; /* Space between each gesture section */
        }
        
        .detectOnClick h3 {
            margin: 5px 0; /* Reduced margin for the heading */
        }
        
        .detectOnClick img {
            width: 80%; /* Make images responsive */
            max-width: 500px; /* Limit maximum width */
            height: auto; /* Maintain aspect ratio */
            cursor: pointer; /* Change cursor to pointer on hover */
            display: block; /* Ensures the image is on its own line */
            margin: 10px auto; /* Center the image with optional spacing */
        }        
    
        /* FOR MY OUTPUT BOX */
        #gestureOutputText {
            text-align: center; /* Center the text horizontally */
            resize: none; /* Prevent resizing */
            overflow: hidden; /* Hide overflow */
            height: 10px; /* Allow height to adjust */
            min-height: 50px; /* Set a minimum height */
            font-size: 44px; /* Increase font size */
        }
        
        .output {
            font-size: 54px; /* Increase font size for the gesture output paragraph */
        }   
    
        .button-container {
            display: flex; /* Use flexbox for layout */
            justify-content: center; /* Center the buttons */
            margin-top: 16px; /* Space above the button container */
            flex-wrap: wrap; /* Allow wrapping for small screens */
        }
        
        /* FOR MY CAPTURE BUTTON AND CLEAR BUTTON */
        .button-container button {
            margin: 0 10px; /* Add space between buttons */
            padding: 10px 20px; /* Increase padding for touch targets */
            font-size: 1em; /* Adjust font size */
            min-width: 120px; /* Set minimum width for buttons */
        }        
    
        /* Media Queries for Mobile Devices */
        @media (max-width: 600px) {
            body {
                margin: 1em;
            }
            video {
                width: 50%;
            }
            .videoView {
                min-height: 300px;
                padding: 1em; /* Adjust padding for mobile */
            }
            .videoView button,
            .videoView a {
                font-size: 1.2em; /* Increase button text size for touch */
            }
            .button-container {
                flex-direction: column; /* Stack buttons vertically on small screens */
                align-items: center; /* Center the buttons */
            }
        }        
    </style>    

</head>
<body>
    <h1>Hand Gesture and Voice Recognition</h1>

    <section id="demos" class="invisible">
        <h2>Demo: Recognize gestures</h2>
        <p><em>Guide Example of Hand Gestures to present</em> in our camera preview</p>

        <!-- FOR MY GUIDE IMAGESSSSSSSSSSSSSSSSSSSSSSSS -->
        <div class="detectOnClick">
            <h3><br>Letter A Gesture</h3>
            <img src="A.jpg" alt="Gesture A" />
        </div>
        <div class="detectOnClick">
            <h3><br>Letter B Gesture</h3>
            <img src="B.jpg" alt="Gesture B" />
        </div>
        <!-- FOR MY GUIDE IMAGESSSSSSSSSSSSSSSSSSSSSSSS -->

        <h2><br>Demo: Camera continuous Hand Gesture detection</h2>
        <p>Use your hand to make gestures in front of the camera to get gesture classification. Click <b>enable camera</b> below and grant access to the camera if prompted.</p>

       <!-- FOR MY TWO BUTTONSSSSSSSSSSSSSSSSSSSSSS -->
<div id="liveView" class="videoView">
    <button id="webcamButton" class="mdc-button mdc-button--raised">
        <span class="mdc-button__ripple"></span>
        <span class="mdc-button__label">ENABLE CAMERA</span>
    </button>
    
    <a href="Voice Recognition.html" class="mdc-button mdc-button--raised">
        <span class="mdc-button__ripple"></span>
        <span class="mdc-button__label">OPEN VOICE RECOGNITION</span>
    </a>

    <a href="Library.html" class="mdc-button mdc-button--raised">
        <span class="mdc-button__ripple"></span>
        <span class="mdc-button__label">OPEN LIBRARY</span>
    </a>
    
    <div style="position: relative; margin-top: 0px;">
        <video id="webcam" autoplay playsinline></video>
        <canvas class="output_canvas" id="output_canvas" width="1280" height="720" style="position: absolute; left: 0; top: 0;"></canvas>
        <p id='gesture_output' class="output"></p>
    </div>
    
    <textarea id="gestureOutputText" rows="4" style="margin-top: 0px; width: 100%; text-align: center;" readonly></textarea>
</div>
<!-- FOR MY TWO BUTTONSSSSSSSSSSSSSSSSSSSSSS -->

<!-- FOR MY CAPTURE AND CLEAR BUTTONNNNNNNNNNNNNNNNNN -->
<div class="button-container">
    <button id="captureButton" class="mdc-button mdc-button--raised" style="margin-top: 16px;">CAPTURE GESTURE</button>
    <button id="clearButton" class="mdc-button mdc-button--raised" style="margin-top: 16px;">CLEAR OUTPUT</button>
</div>        
<!-- FOR MY CAPTURE AND CLEAR BUTTONNNNNNNNNNNNNNNNNN -->

    </section>
    
<!--JAVA SCRIPTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTTT-->
    <!-- Material Components JavaScript -->
    <script src="https://unpkg.com/material-components-web@latest/dist/material-components-web.min.js"></script>
    
    <script type="module">
        /* FOR CAPTURING LETTER OUTPUTTTTTTTTTTTTTTTTTTTTTTTTTT */   
        const captureButton = document.getElementById("captureButton");
        const gestureOutputText = document.getElementById("gestureOutputText");
        
        captureButton.addEventListener("click", () => {
            if (results && results.gestures.length > 0) {
                const categoryName = results.gestures[0][0].categoryName;
                gestureOutputText.value += categoryName + ""; // Append recognized gesture
            } else {
                gestureOutputText.value += " "; // Append space if no gesture detected
            }
        });  
    
        function captureGesture() {
            if (results && results.gestures.length > 0) {
                const categoryName = results.gestures[0][0].categoryName;
                gestureOutputText.value += categoryName; // Change this to the appropriate gesture letter as needed
            }
        }
        /* FOR CAPTURING LETTER OUTPUTTTTTTTTTTTTTTTTTTTTTTTTTT */ 
    
        /* FOR REMOVING LETTER OUTPUT */ 
        const clearButton = document.getElementById("clearButton");
    
        clearButton.addEventListener("click", () => {
            gestureOutputText.value = ""; // Clear the text area
        });
        /* FOR REMOVING LETTER OUTPUT */ 
    
        import {
            GestureRecognizer,
            FilesetResolver,
            DrawingUtils
        } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";
    
        const demosSection = document.getElementById("demos");
        let gestureRecognizer;
        let runningMode = "IMAGE";
        let enableWebcamButton;
        let webcamRunning = false;
        const videoHeight = "660px"; /* 360 */
        const videoWidth = "780px"; /* 480 */
    
        const createGestureRecognizer = async () => {
            const vision = await FilesetResolver.forVisionTasks(
                "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
            );
            gestureRecognizer = await GestureRecognizer.createFromOptions(vision, {
                baseOptions: {
                    modelAssetPath: "https://raw.githubusercontent.com/vinceflores123/datasets/main/datasets%20a%20to%20z2.task",
                    delegate: "CPU"
                },
            });
            demosSection.classList.remove("invisible");
        };
        createGestureRecognizer();
    
        const imageContainers = document.getElementsByClassName("detectOnClick");
        for (let i = 0; i < imageContainers.length; i++) {
            imageContainers[i].children[0].addEventListener("click", handleClick);
        }
    
        async function handleClick(event) {
            if (!gestureRecognizer) {
                alert("Please wait for gestureRecognizer to load");
                return;
            }
    
            if (runningMode === "VIDEO") {
                runningMode = "IMAGE";
                await gestureRecognizer.setOptions({ runningMode: "IMAGE" });
            }
    
            const allCanvas = event.target.parentNode.getElementsByClassName("canvas");
            for (var i = allCanvas.length - 1; i >= 0; i--) {
                allCanvas[i].parentNode.removeChild(allCanvas[i]);
            }
    
            const results = gestureRecognizer.recognize(event.target);
            console.log(results);
            if (results.gestures.length > 0) {
                const p = event.target.parentNode.childNodes[3];
                p.setAttribute("class", "info");
    
                const categoryName = results.gestures[0][0].categoryName;
                const categoryScore = parseFloat(results.gestures[0][0].score * 100).toFixed(2);
                const handedness = results.handednesses[0][0].displayName;
    
                p.innerText = `GestureRecognizer: ${categoryName}\n Confidence: ${categoryScore}%\n Handedness: ${handedness}`;
                p.style = "left: 0px; top: " + event.target.height + "px; width: " + (event.target.width - 10) + "px;";
            }
        }
    
        const video = document.getElementById("webcam");
        const canvasElement = document.getElementById("output_canvas");
        const canvasCtx = canvasElement.getContext("2d");
        const gestureOutput = document.getElementById("gesture_output");
    
        function hasGetUserMedia() {
            return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
        }
    
        if (hasGetUserMedia()) {
            enableWebcamButton = document.getElementById("webcamButton");
            enableWebcamButton.addEventListener("click", enableCam);
        } else {
            console.warn("getUserMedia() is not supported by your browser");
        }
    
        function enableCam(event) {
            if (!gestureRecognizer) {
                alert("Please wait for gestureRecognizer to load");
                return;
            }
    
            webcamRunning = !webcamRunning;
            enableWebcamButton.innerText = webcamRunning ? "DISABLE PREDICTIONS" : "ENABLE PREDICTIONS";
    
            const constraints = { video: true };
    
            navigator.mediaDevices.getUserMedia(constraints).then(function (stream) {
                video.srcObject = stream;
                video.addEventListener("loadeddata", predictWebcam);
            });
        }
    
        let lastVideoTime = -1;
        let results = undefined;
        
         /* FOR LANDMARKS AND BOUNDING BOXXXXXXXXXXXX */ 
        async function predictWebcam() {
            if (runningMode === "IMAGE") {
                runningMode = "VIDEO";
                await gestureRecognizer.setOptions({ runningMode: "VIDEO" });
            }
            let nowInMs = Date.now();
            if (video.currentTime !== lastVideoTime) {
                lastVideoTime = video.currentTime;
                results = gestureRecognizer.recognizeForVideo(video, nowInMs);
            }
        
            canvasCtx.save();
            canvasCtx.clearRect(0, 0, canvasElement.width, canvasElement.height);
            const drawingUtils = new DrawingUtils(canvasCtx);
        
            canvasElement.style.height = videoHeight;
            video.style.height = videoHeight;
            canvasElement.style.width = videoWidth;
            video.style.width = videoWidth;
        
            if (results.landmarks) {
                for (const landmarks of results.landmarks) {
                    // Draw connectors and landmarks (optional, uncomment if needed)
                    // drawingUtils.drawConnectors(landmarks, GestureRecognizer.HAND_CONNECTIONS, {
                    //     color: "#00FF00",
                    //     lineWidth: 5
                    // });
                    // drawingUtils.drawLandmarks(landmarks, {
                    //     color: "#FF0000",
                    //     lineWidth: 2
                    // });
        
                    // Calculate bounding box
                    const xCoords = landmarks.map(point => point.x);
                    const yCoords = landmarks.map(point => point.y);
                    const minX = Math.min(...xCoords);
                    const maxX = Math.max(...xCoords);
                    const minY = Math.min(...yCoords);
                    const maxY = Math.max(...yCoords);
        
                    // Draw bounding box
                    const boxPadding = 10; // Add some padding
                    canvasCtx.strokeStyle = '#00FF00'; // Color of the bounding box (green)
                    canvasCtx.lineWidth = 4;
                    canvasCtx.strokeRect(minX * canvasElement.width - boxPadding, minY * canvasElement.height - boxPadding,
                                         (maxX - minX) * canvasElement.width + boxPadding * 2, 
                                         (maxY - minY) * canvasElement.height + boxPadding * 2);
                }
            }
        
            canvasCtx.restore();
            if (results.gestures.length > 0) {
                gestureOutput.style.display = "block";
                const categoryName = results.gestures[0][0].categoryName;
                const categoryScore = parseFloat(results.gestures[0][0].score * 100).toFixed(2);
                const originalHandedness = results.handednesses[0][0].displayName;
                const handedness = (originalHandedness === 'Right') ? 'Left' : 'Right';
        
                gestureOutput.innerText = `GestureRecognizer: ${categoryName}\n Confidence: ${categoryScore} %\n Handedness: ${handedness}`;
            } else {
                gestureOutput.style.display = "none";
            }
        
            if (webcamRunning === true) {
                window.requestAnimationFrame(predictWebcam);
            }
        }
        /* FOR LANDMARKS AND BOUNDING BOXXXXXXXXXXXX */ 
        
    </script>
    
</body>
</html>
